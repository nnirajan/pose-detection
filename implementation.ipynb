{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00d0914-5846-4847-88ea-41dbaf471a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe version: 0.10.21\n",
      "OpenCV version: 4.11.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "print(\"MediaPipe version:\", mp.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2053090c-5a9a-42af-9455-19e1476dba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743269899.442280 3182299 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "# # Initialize MediaPipe Pose module\n",
    "mp_drawing = mp.solutions.drawing_utils  # Utility to draw landmarks\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence = 0.5, min_tracking_confidence = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a47266-6495-40ae-929b-54b5c9809070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate the angle between three points using the cosine rule.\"\"\"\n",
    "    a = np.array(a)  # Shoulder\n",
    "    b = np.array(b)  # Elbow\n",
    "    c = np.array(c)  # Wrist\n",
    "\n",
    "    # Vectors\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "\n",
    "    # Compute angle\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))  # Ensure within valid range\n",
    "    \n",
    "    return np.degrees(angle)  # Convert to degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd06072-61ec-4c15-aa20-6048751f41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for bicep curl detection\n",
    "# Initialize counting variables\n",
    "bicep_count = 0\n",
    "arm_position = None  # Track whether the arm is \"up\" or \"down\"\n",
    "elbow_threshold_up = 150  # Angle threshold for \"arm extended\"\n",
    "elbow_threshold_down = 50  # Angle threshold for \"arm flexed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff36062-af35-4cb9-9d30-2d9908790ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Keep asking for a valid input until provided\n",
    "# choice = \"\"\n",
    "# while choice not in ['1', '2']:\n",
    "#     print(\"\\nChoose the video source:\")\n",
    "#     print(\"1. Camera\")\n",
    "#     print(\"2. Select Video File\")\n",
    "#     choice = input(\"Enter '1' for camera or '2' for video file: \").strip()\n",
    "\n",
    "#     if not choice:  # Handle empty input\n",
    "#         print(\"Invalid input. Please enter '1' or '2'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be60847-a7bb-4718-9da5-cd0c2b7373ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743269899.502441 3182422 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743269899.514121 3182422 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743269901.200201 3182426 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "2025-03-29 23:23:21.556 python[65515:3182299] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-29 23:23:21.556 python[65515:3182299] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting camera feed...\n"
     ]
    }
   ],
   "source": [
    "# Function to open the webcam and display the feed with pose detection\n",
    "def open_camera_with_pose():\n",
    "    global bicep_count, arm_position, elbow_threshold_up, elbow_threshold_down\n",
    "    \n",
    "    \"\"\"Open the webcam and display the live feed.\"\"\"\n",
    "    # 0 is the default camera (usually the built-in webcam)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Check if the video source opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the camera.\")\n",
    "        return\n",
    "\n",
    "    # Read and display frames\n",
    "    # Loop to keep the feed open until 'q' is pressed\n",
    "    while True:\n",
    "        ret, frame = cap.read() # Capture frame-by-frame\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame from BGR (OpenCV format) to RGB (MediaPipe format)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame and get pose landmarks\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        # If landmarks are found, draw them on the frame\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # Extract important landmarks (example: shoulders and elbows)\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extract keypoints (Right arm)\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "            elbow = landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "            wrist = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "            # Convert to pixel coordinates\n",
    "            h, w, _ = frame.shape\n",
    "            shoulder_coords = (int(shoulder.x * w), int(shoulder.y * h))\n",
    "            elbow_coords = (int(elbow.x * w), int(elbow.y * h))\n",
    "            wrist_coords = (int(wrist.x * w), int(wrist.y * h))\n",
    "\n",
    "            # # Draw circles on keypoints\n",
    "            cv2.circle(frame, shoulder_coords, 8, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, elbow_coords, 8, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, wrist_coords, 8, (0, 0, 255), -1)\n",
    "\n",
    "            # Display coordinates\n",
    "            cv2.putText(frame, f\"Shoulder: {shoulder_coords}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Elbow: {elbow_coords}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Wrist: {wrist_coords}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "            # Calculate elbow angle\n",
    "            elbow_angle = calculate_angle(shoulder_coords, elbow_coords, wrist_coords)\n",
    "\n",
    "            # Display the angle\n",
    "            cv2.putText(frame, f\"Elbow Angle: {int(elbow_angle)}Â°\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "            # Initialize arm position if it's the first frame\n",
    "            # if arm_position is None:\n",
    "            #     arm_position = \"down\" if elbow_angle > elbow_threshold_up else \"up\"\n",
    "            \n",
    "            # Biceps curl repetition logic\n",
    "            if elbow_angle > elbow_threshold_up:\n",
    "                arm_position = \"down\"  # Arm is extended\n",
    "                \n",
    "            elif elbow_angle < elbow_threshold_down and arm_position == \"down\":\n",
    "                arm_position = \"up\"  # Arm is flexed\n",
    "                bicep_count += 1  # Count one repetition\n",
    "\n",
    "            # Display the repetition count\n",
    "            cv2.putText(frame, f\"Reps: {bicep_count}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "        # Display the frame with the pose landmarks\n",
    "        cv2.imshow(\"Camera Feed\", frame)  # Show the live video feed\n",
    "\n",
    "        # Exit if 'q' is pressed\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"Exiting camera feed...\")\n",
    "            break\n",
    "            \n",
    "    # Release the camera and close the OpenCV window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() # Close the window properly\n",
    "\n",
    "# Call the function to start the camera with pose detection\n",
    "open_camera_with_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3561b8d1-8cb3-4a1a-bd96-5eb60e1420ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if choice == '1':\n",
    "#     # Step 2: Open the webcam (Camera option)\n",
    "#     # Call the function to open the camera\n",
    "#     open_camera()\n",
    "    \n",
    "# elif choice == '2':\n",
    "#     # Step 3: Open file dialog to choose a video file (Video file option)\n",
    "#     root = tk.Tk()\n",
    "#     root.withdraw()  # Hide the main tkinter window\n",
    "#     root.call('wm', 'attributes', '.', '-topmost', True)  # Bring the dialog to the front\n",
    "#     file_path = filedialog.askopenfilename(title=\"Select Video File\", filetypes=[(\"MP4 files\", \"*.mp4\"), (\"All files\", \"*.*\")])\n",
    "\n",
    "#     if not file_path:\n",
    "#         print(\"No file selected. Exiting.\")\n",
    "#         exit()\n",
    "\n",
    "#     cap = cv2.VideoCapture(file_path)  # Open the selected video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f43c0e-a5e1-4e6e-accd-578cd0a066e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
